{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename):\n",
    "    fr = open(filename,'r')\n",
    "    x,y = [],[]\n",
    "    for line in fr.readlines():\n",
    "        curline = line.strip().split(',')\n",
    "        x.append([int(int(num) >= 128) for num in curline[1:]])\n",
    "        y.append(int(curline[0]))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,label,dims,leaves):\n",
    "        self.label = label\n",
    "        self.dims = dims\n",
    "        self.leaves = leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_label(labels):\n",
    "    return Counter(labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_entropy(labels):\n",
    "    entropy = 0\n",
    "    labelset = set(labels)\n",
    "    for i in labelset:\n",
    "        entropy -= (np.sum(labels==i)/labels.shape[0]) * np.log2(np.sum(labels==i)/labels.shape[0])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_conditional_entropy(features,labels):\n",
    "    conditional_entropy = 0\n",
    "    labelset = set(features)\n",
    "    for i in labelset:\n",
    "        conditional_entropy += np.sum(features == i) / labels.shape[0] * cal_entropy(labels[features == i])\n",
    "    return conditional_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_feature(x_train,y_train,features_left):\n",
    "    best_feature = -1\n",
    "    max_gain = float(\"-inf\")\n",
    "    for i in features_left:\n",
    "        gain = cal_entropy(y_train)\n",
    "        gain -= cal_conditional_entropy(x_train[:,i],y_train)\n",
    "        if max_gain < gain:\n",
    "            max_gain = gain\n",
    "            best_feature = i\n",
    "    return best_feature,max_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Tree(x_train,y_train,features_left,threshold):\n",
    "    if len(set(y_train)) == 1: return Node(y_train[0],-1,None)\n",
    "    if not features_left: \n",
    "        return Node(major_label(y_train),-1,None)\n",
    "    best_feature,max_gain = get_best_feature(x_train,y_train,features_left)\n",
    "    if max_gain < threshold: \n",
    "        return Node(major_label(y_train),-1,None)\n",
    "    features = set(x_train[:,best_feature])\n",
    "    leaves = {}\n",
    "    features_copy = copy.deepcopy(features_left)\n",
    "    features_copy.remove(best_feature)\n",
    "    for feature in features:\n",
    "        leaves[feature] = build_Tree(x_train[x_train[:,best_feature] == feature],y_train[x_train[:,best_feature] == feature] \\\n",
    "                      ,features_copy,threshold)\n",
    "    return Node(-1,best_feature,leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,root):\n",
    "    cur_node = root\n",
    "    while cur_node.dims != -1:\n",
    "        cur_node = cur_node.leaves[x[cur_node.dims]]\n",
    "    return cur_node.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_val,y_val,root):\n",
    "    size = x_val.shape[0]\n",
    "    correct = 0\n",
    "    for i in range(size):\n",
    "        label = predict(x_val[i],root)\n",
    "        if label == y_val[i]: correct += 1\n",
    "    return correct / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the decision tree consumes 635.58 .\n",
      "Accuracy of the train dataset is 1.00\n",
      "Accuracy of the val dataset is 0.87\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = loadData('./input/mnist_train.csv')\n",
    "x_val,y_val = loadData('./input/mnist_test.csv')\n",
    "start = time.time()\n",
    "root = build_Tree(x_train,y_train,[i for i in range(784)],float(\"-inf\"))\n",
    "print(\"Building the decision tree consumes {:.2f} .\".format(time.time() - start))\n",
    "acc_train = test(x_train,y_train,root)\n",
    "print(\"Accuracy of the train dataset is {:.2f}\".format(acc_train))\n",
    "acc_val = test(x_val,y_val,root)\n",
    "print(\"Accuracy of the val dataset is {:.2f}\".format(acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
